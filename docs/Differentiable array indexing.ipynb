{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "Using gradient descent, find the correct array _index_ to set to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax import value_and_grad, jit, lax, random\n",
    "from jax.ops import index_update\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.zeros(10)\n",
    "target_index = 3\n",
    "Y[3] = 1.0\n",
    "\n",
    "plt.figure(figsize=(14, 3))\n",
    "plt.stem(Y, basefmt=' ')\n",
    "_ = plt.title('Target function', size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(X, Y):\n",
    "    return 1 - jnp.correlate(X, Y).mean()\n",
    "\n",
    "def mse(X, Y):\n",
    "    return ((Y - X) ** 2).mean()\n",
    "\n",
    "def mae(X, Y):\n",
    "    return jnp.abs(Y - X).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_index(index, key=None):\n",
    "    X = jnp.zeros(Y.size)\n",
    "    return index_update(X, index.astype('int32'), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interp_index(index, key=None):\n",
    "    X = jnp.zeros(Y.size)\n",
    "    i0 = jnp.floor(index)\n",
    "    i1 = i0 + 1\n",
    "    X = index_update(X, i0.astype('int32'), (i1 - index))\n",
    "    X = index_update(X, i1.astype('int32'), (index - i0))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_interp_index(index, num_mean, key=None):\n",
    "    X = jnp.zeros(Y.size)\n",
    "    i0 = jnp.floor(index)\n",
    "    i1 = i0 + 1\n",
    "    X = index_update(X, i0.astype('int32'), (i1 - index))\n",
    "    X = index_update(X, i1.astype('int32'), (index - i0))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x,x0,sigma):\n",
    "    return jnp.exp(-((x - x0) / sigma)**2 / 2)\n",
    "\n",
    "def gaussian_interp_index(index, key=None):\n",
    "    return gaussian(jnp.arange(Y.size), index, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_sample_index(index, key):\n",
    "    weights = gaussian(jnp.arange(Y.size), index, 3.0)\n",
    "    discrete_index = random.choice(key, Y.size, p=weights)\n",
    "    index_array = jnp.zeros(Y.size)\n",
    "    return index_update(index_array, discrete_index, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "def window(size):\n",
    "    return signal.blackmanharris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangle(X, center):\n",
    "    return 1 - jnp.abs(X - center) / jnp.max(X - center)\n",
    "\n",
    "def triangle_interp_index(index):\n",
    "    return triangle(jnp.arange(Y.size), index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_loss(index_guess, create_indices_fn, key):\n",
    "    X = create_indices_fn(index_guess, key=key)\n",
    "    return mse(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def optimize(create_indices_fn, index_guess, steps=10):\n",
    "    key = random.PRNGKey(0)\n",
    "    loss_fn = partial(index_loss, create_indices_fn=create_indices_fn)\n",
    "    grad_fn = jit(value_and_grad(loss_fn))\n",
    "    estimated_index = index_guess\n",
    "    initial_loss, _ = grad_fn(estimated_index, key=key)\n",
    "    key, subkey = random.split(key)\n",
    "    for train_i in range(steps):\n",
    "        loss, grad = grad_fn(estimated_index, key=key)\n",
    "        key, subkey = random.split(key)\n",
    "        estimated_index -= grad\n",
    "    return estimated_index, initial_loss, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optimized_indexes(create_indices_fn, start_indices=np.linspace(0, Y.size - 1, 90, endpoint=False), steps=20):\n",
    "    fig, plots = plt.subplots(3, 1, figsize=(14, 8))\n",
    "    estimated_index_plot, initial_loss_plot, optimized_loss_plot = plots\n",
    "    optimized = np.array([optimize(create_indices_fn, start_index, steps=steps) for start_index in start_indices])\n",
    "    estimated_index_plot.plot(start_indices, optimized[:,0], linewidth=3)\n",
    "    estimated_index_plot.set_title('Estimated index', size=18)\n",
    "    estimated_index_plot.set_ylabel('Estimated index after {} steps'.format(steps), size=11)\n",
    "    estimated_index_plot.axhline(target_index, linestyle='--', c='r', label='Target index')\n",
    "    estimated_index_plot.legend()\n",
    "    initial_loss_plot.plot(start_indices, optimized[:,1], linewidth=3)\n",
    "    initial_loss_plot.set_title('Initial loss', size=18)\n",
    "    initial_loss_plot.set_ylabel('Initial MSE loss'.format(steps), size=11)\n",
    "    optimized_loss_plot.plot(start_indices, optimized[:,2], linewidth=3)\n",
    "    optimized_loss_plot.set_title('Optimized loss', size=18)\n",
    "    optimized_loss_plot.set_xlabel('Initial guess for index value', size=16)\n",
    "    optimized_loss_plot.set_ylabel('MSE loss after {} steps'.format(steps), size=11)\n",
    "    for plot in plots:\n",
    "        plot.grid(True)\n",
    "        plot.set_xticks(np.arange(Y.size))\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimized_indexes(single_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimized_indexes(linear_interp_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's happening is that at the edges, moving the gaussian distribution removes some of the mass from the\n",
    "# smooth-indexing array that's being compared with target array (unit impulse at some target index).\n",
    "# As mass is removed, MSE loss decreases since the area under the gaussian curve and the zeros in the target\n",
    "# array decreases.\n",
    "# TODO might be able to extend the successful range by using a different distribution.\n",
    "# Ideal distribution would be smooth, with constant area under the curve, extending the full window,\n",
    "# with skew centered around a parameter.\n",
    "# There's also https://stackoverflow.com/questions/46926809/getting-around-tf-argmax-which-is-not-differentiable\n",
    "plot_optimized_indexes(gaussian_interp_index, steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimized_indexes(gaussian_sample_index, steps=20) # don't get why this is constant optimized loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed = jnp.zeros(Y.size)\n",
    "key = random.PRNGKey(0)\n",
    "for _ in range(100):\n",
    "    a = gaussian_sample_index(4.2, key)\n",
    "    key, subkey = random.split(key)\n",
    "    summed += a\n",
    "summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about exploring different distance measures that could provide a gradient for similar,\n",
    "# but delayed, signals  (as opposed to MSE)?\n",
    "\n",
    "# https://docs.scipy.org/doc/scipy/reference/spatial.distance.html\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import wasserstein_distance\n",
    "# from fastdtw import fastdtw\n",
    "\n",
    "# def dtw(x, y):\n",
    "#     dist, path = fastdtw(x, y, dist=distance.euclidean)\n",
    "#     return dist\n",
    "\n",
    "distance_measures = [\n",
    "    distance.braycurtis,\n",
    "    distance.canberra,\n",
    "    distance.chebyshev,\n",
    "    distance.cityblock,\n",
    "    distance.correlation,\n",
    "    distance.cosine,\n",
    "    distance.euclidean,\n",
    "    distance.jensenshannon,\n",
    "    distance.minkowski,\n",
    "    distance.sqeuclidean,\n",
    "    wasserstein_distance,\n",
    "#     fastdtw(x, y, dist=distance.euclidean)\n",
    "#    dtw,\n",
    "]\n",
    "\n",
    "def array_with_one_at(i):\n",
    "    ar = np.zeros(8)\n",
    "    ar[i] = 1.0\n",
    "    return ar\n",
    "\n",
    "a = array_with_one_at(2)\n",
    "\n",
    "{distance_measure.__name__: ['{:.2f}'.format(distance_measure(a, array_with_one_at(i))) for i in range(a.size)] for distance_measure in distance_measures}\n",
    "# Nope - these all have the same distance regardless of the `1.0` position.\n",
    "# That is, none seem to be order-dependent :( Even DTW doesn't seem right for this simple 1d case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
